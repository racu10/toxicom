{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['aww', 'match', 'background', 'colour', 'seem...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['make', 'real', 'suggestion', 'improvement', ...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['congratulation', 'well', 'use', 'tool', 'wel...</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['cocksucker', 'piss', 'around', 'work']</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['vandalism', 'matt', 'shirvington', 'article'...</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sorry', 'word', 'nonsense', 'offensive', 'an...</td>\n",
       "      <td>sorry word nonsense offensive anyway intending...</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['alignment', 'subject', 'contrary', 'dulithgow']</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>&lt;class 'dict'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "5           5  00025465d4725e87   \n",
       "6           6  0002bcb3da6cb337   \n",
       "7           7  00031b1e95af7921   \n",
       "8           8  00037261f536c51d   \n",
       "9           9  00040093b2687caa   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9  alignment on this subject and which are contra...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "5        0       0       0              0   \n",
       "6        1       0       1              0   \n",
       "7        0       0       0              0   \n",
       "8        0       0       0              0   \n",
       "9        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  ['explanation', 'edits', 'made', 'username', '...   \n",
       "1  ['aww', 'match', 'background', 'colour', 'seem...   \n",
       "2  ['hey', 'man', 'really', 'trying', 'edit', 'wa...   \n",
       "3  ['make', 'real', 'suggestion', 'improvement', ...   \n",
       "4      ['sir', 'hero', 'chance', 'remember', 'page']   \n",
       "5  ['congratulation', 'well', 'use', 'tool', 'wel...   \n",
       "6           ['cocksucker', 'piss', 'around', 'work']   \n",
       "7  ['vandalism', 'matt', 'shirvington', 'article'...   \n",
       "8  ['sorry', 'word', 'nonsense', 'offensive', 'an...   \n",
       "9  ['alignment', 'subject', 'contrary', 'dulithgow']   \n",
       "\n",
       "                                    cleanWordsAsText      BagOfWords  \n",
       "0  explanation edits made username hardcore metal...  <class 'dict'>  \n",
       "1  aww match background colour seemingly stuck th...  <class 'dict'>  \n",
       "2  hey man really trying edit war guy constantly ...  <class 'dict'>  \n",
       "3  make real suggestion improvement wondered sect...  <class 'dict'>  \n",
       "4                      sir hero chance remember page  <class 'dict'>  \n",
       "5             congratulation well use tool well talk  <class 'dict'>  \n",
       "6                        cocksucker piss around work  <class 'dict'>  \n",
       "7  vandalism matt shirvington article reverted pl...  <class 'dict'>  \n",
       "8  sorry word nonsense offensive anyway intending...  <class 'dict'>  \n",
       "9               alignment subject contrary dulithgow  <class 'dict'>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameTrainCSV = 'trainWithListOfCleanWords'\n",
    "nameTestCSV = 'testWithListOfCleanWords'\n",
    "\n",
    "train = pd.read_csv('../data/processed/' + nameTrainCSV + '.csv', encoding='utf-8')\n",
    "train['BagOfWords'] = dict\n",
    "train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.379764080047607\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in range(len(train)):\n",
    "    train.set_value(col='listOfCleanWords',\n",
    "                index=x,\n",
    "                value=ast.literal_eval(train[\"listOfCleanWords\"][x]))\n",
    "    train.set_value(col='BagOfWords',\n",
    "                index=x,\n",
    "                value=Counter(train[\"listOfCleanWords\"][x]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>listOfCleanWords</th>\n",
       "      <th>cleanWordsAsText</th>\n",
       "      <th>BagOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>{'explanation': 1, 'edits': 1, 'made': 1, 'use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>{'aww': 1, 'match': 1, 'background': 1, 'colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>{'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "      <td>{'make': 1, 'real': 1, 'suggestion': 1, 'impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>{'sir': 1, 'hero': 1, 'chance': 1, 'remember':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                    listOfCleanWords  \\\n",
       "0  [explanation, edits, made, username, hardcore,...   \n",
       "1  [aww, match, background, colour, seemingly, st...   \n",
       "2  [hey, man, really, trying, edit, war, guy, con...   \n",
       "3  [make, real, suggestion, improvement, wondered...   \n",
       "4                [sir, hero, chance, remember, page]   \n",
       "\n",
       "                                    cleanWordsAsText  \\\n",
       "0  explanation edits made username hardcore metal...   \n",
       "1  aww match background colour seemingly stuck th...   \n",
       "2  hey man really trying edit war guy constantly ...   \n",
       "3  make real suggestion improvement wondered sect...   \n",
       "4                      sir hero chance remember page   \n",
       "\n",
       "                                          BagOfWords  \n",
       "0  {'explanation': 1, 'edits': 1, 'made': 1, 'use...  \n",
       "1  {'aww': 1, 'match': 1, 'background': 1, 'colou...  \n",
       "2  {'hey': 1, 'man': 1, 'really': 1, 'trying': 1,...  \n",
       "3  {'make': 1, 'real': 1, 'suggestion': 1, 'impro...  \n",
       "4  {'sir': 1, 'hero': 1, 'chance': 1, 'remember':...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTICLASS PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classLabel = {\n",
    "    0: \"neutral\",\n",
    "    1: \"toxic\",\n",
    "    2 : \"severe_toxic\",\n",
    "    3 : \"obscene\",\n",
    "    4 : \"threat\",\n",
    "    5 : \"insult\",\n",
    "    6 : \"identity_hate\" \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.empty((len(train['cleanWordsAsText']),),dtype=object)\n",
    "allTextToxicTrain = dict()\n",
    "for idx in classLabel:\n",
    "    if classLabel[idx] != \"neutral\":\n",
    "        T = np.where(train[classLabel[idx]] == 1)[0]\n",
    "        allTextToxicTrain[idx] = T\n",
    "        for i in T:\n",
    "            if y[i] is None:\n",
    "                y[i] = [idx]                \n",
    "            else:\n",
    "                y[i].append(idx)\n",
    "indxsOfNeutralTexts = np.where(y == None) \n",
    "y[indxsOfNeutralTexts] = [[0]]\n",
    "indxsOfNeutralTexts = indxsOfNeutralTexts[0]\n",
    "\n",
    "allTextsNoToxicTrain = [str(train['cleanWordsAsText'][x]) for x in indxsOfNeutralTexts]\n",
    "\n",
    "idxList = []\n",
    "for i in allTextToxicTrain.keys():\n",
    "    #allTextToxicTrain[i] = [str(train['cleanWordsAsText'][j]) for j in allTextToxicTrain[i]]\n",
    "    idxList = np.unique(np.append(idxList, allTextToxicTrain[i]))\n",
    "allTextToxicTrain = [str(train['cleanWordsAsText'][j]) for j in idxList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### GET THE BEST WORDS IN ALL CORPUS #####\n",
    "\n",
    "topNFeatures = 1000\n",
    "Nfolds = 5\n",
    "\n",
    "#Neutral data\n",
    "\n",
    "tdidfVectTrainNoToxic = TfidfVectorizer(max_features=topNFeatures)\n",
    "matrixTdidfTrainNoToxic = tdidfVectTrainNoToxic.fit_transform(allTextsNoToxicTrain)\n",
    "\n",
    "featureArrayNoToxicTrain = np.array(tdidfVectTrainNoToxic.get_feature_names())\n",
    "tfidfOrderedNoToxicTrain = np.argsort(matrixTdidfTrainNoToxic.toarray()).flatten()[::-1]\n",
    "selectedWordsTrainNoToxic = featureArrayNoToxicTrain[tfidfOrderedNoToxicTrain][:topNFeatures]\n",
    "\n",
    "#Toxic data\n",
    "selectedWordsTrainToxic = []\n",
    "selectedWordsTrain = []\n",
    "\n",
    "tdidfVectTrainToxic = TfidfVectorizer(max_features=topNFeatures)\n",
    "matrixTdidfTrainToxic = tdidfVectTrainToxic.fit_transform(allTextToxicTrain)\n",
    "featureArrayToxicTrain = np.array(tdidfVectTrainToxic.get_feature_names())\n",
    "tfidfOrderedToxicTrain = np.argsort(matrixTdidfTrainToxic.toarray()).flatten()[::-1]\n",
    "selectedWordsTrainToxic = featureArrayToxicTrain[tfidfOrderedToxicTrain][:topNFeatures]\n",
    "\n",
    "# Get words\n",
    "for x in range(topNFeatures):\n",
    "    if len(selectedWordsTrain) <= topNFeatures: \n",
    "        words = [selectedWordsTrainToxic[x]] + [selectedWordsTrainNoToxic[x]]\n",
    "        selectedWordsTrain = np.unique(np.append(selectedWordsTrain, np.unique(words)))    \n",
    "selectedWordsTrain = selectedWordsTrain[:topNFeatures]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allTrainText = [txt if txt is not np.nan else '' for txt in train['cleanWordsAsText']]\n",
    "\n",
    "X = allTrainText\n",
    "yBinary = MultiLabelBinarizer().fit_transform(y)\n",
    "\n",
    "kf = KFold(n_splits=Nfolds, random_state=True)\n",
    "kf.get_n_splits(allTrainText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICCION MULTICLASS Linear SVC\n",
    "\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = [X[i] for i in train_index]\n",
    "    X_test = [X[i] for i in test_index]\n",
    "    y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted)\n",
    "    fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "    print(\"Acc: \" + str(acc))\n",
    "    print(\"Logloss: \" + str(logloss))\n",
    "    print(\"Fmeausre: \" + str(fmeausre))\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "print(\"\\n Linear SVC\")\n",
    "print(\"La precisi贸n media para \" + str(Nfolds) + \" folds es de: \" + str(round(meanAcc, 5)))\n",
    "print(\"Media Logloss: \" + str(round(meanLogLoss, 5)))\n",
    "print(\"Media Fmeasure: \" + str(meanFmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICCION MULTICLASS Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = [X[i] for i in train_index]\n",
    "    X_test = [X[i] for i in test_index]\n",
    "    y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(DecisionTreeClassifier()))])\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted)\n",
    "    fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "    print(\"Acc: \" + str(acc))\n",
    "    print(\"Logloss: \" + str(logloss))\n",
    "    print(\"Fmeausre: \" + str(fmeausre))\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "print(\"\\n Decission tree\")\n",
    "print(\"La precisi贸n media para \" + str(Nfolds) + \" folds es de: \" + str(round(meanAcc, 5)))\n",
    "print(\"Media Logloss: \" + str(round(meanLogLoss, 5)))\n",
    "print(\"Media Fmeasure: \" + str(meanFmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICCION MULTICLASS SGD\n",
    "from sklearn import linear_model\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = [X[i] for i in train_index]\n",
    "    X_test = [X[i] for i in test_index]\n",
    "    y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(linear_model.SGDClassifier()))])\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted)\n",
    "    fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "    print(\"Acc: \" + str(acc))\n",
    "    print(\"Logloss: \" + str(logloss))\n",
    "    print(\"Fmeausre: \" + str(fmeausre))\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "print(\"\\n SGD\")\n",
    "print(\"La precisi贸n media para \" + str(Nfolds) + \" folds es de: \" + str(round(meanAcc, 5)))\n",
    "print(\"Media Logloss: \" + str(round(meanLogLoss, 5)))\n",
    "print(\"Media Fmeasure: \" + str(meanFmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICCION MULTICLASS NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "meanAcc = 0.0\n",
    "meanLogLoss = 0.0\n",
    "meanFmeasure = 0.0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = [X[i] for i in train_index]\n",
    "    X_test = [X[i] for i in test_index]\n",
    "    y_train, y_test = yBinary[train_index], yBinary[test_index]\n",
    "\n",
    "    classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(vocabulary=selectedWordsTrain)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB()))])\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted)\n",
    "    fmeausre = f1_score(y_test, predicted, labels=[0,1,2,3,4,5,6], average=None)\n",
    "    logloss = log_loss(y_pred=predicted, y_true=y_test)\n",
    "    print(\"Acc: \" + str(acc))\n",
    "    print(\"Logloss: \" + str(logloss))\n",
    "    print(\"Fmeausre: \" + str(fmeausre))\n",
    "    meanAcc += acc\n",
    "    meanLogLoss += logloss\n",
    "    meanFmeasure += fmeausre\n",
    "meanAcc = meanAcc / Nfolds\n",
    "meanLogLoss = meanLogLoss / Nfolds\n",
    "meanFmeasure = meanFmeasure / Nfolds\n",
    "print(\"\\n NB\")\n",
    "print(\"La precisi贸n media para \" + str(Nfolds) + \" folds es de: \" + str(round(meanAcc, 5)))\n",
    "print(\"Media Logloss: \" + str(round(meanLogLoss, 5)))\n",
    "print(\"Media Fmeasure: \" + str(meanFmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
